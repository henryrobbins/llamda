{
  "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    return 1 / distance_matrix": {
    "exec_success": true,
    "obj": 6.52143024782235,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    eps = 1e-6  # Small value to avoid division by zero\n    inverted_distances = 1 / (distance_matrix + eps)\n    row_sum = inverted_distances.sum(axis=1)\n    heuristics_matrix = inverted_distances / row_sum[:, np.newaxis]\n    return heuristics_matrix": {
    "exec_success": true,
    "obj": 6.554272933380041,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    with np.errstate(divide='ignore', invalid='ignore'):\n        distances_inverse = 1 / np.where(distance_matrix != 0, distance_matrix, np.inf)\n    \n    min_distances = np.min(distances_inverse, axis=1, where=~np.isnan(distances_inverse))\n    score_matrix = min_distances[:, np.newaxis] * distances_inverse\n    \n    return score_matrix": {
    "exec_success": false,
    "obj": "inf",
    "traceback_msg": "Traceback (most recent call last):\n  File \"/Users/hwr/projects/llamda/llamda/problems/tsp_aco/eval.py\", line 57, in <module>\n    obj = solve(node_pos)\n          ^^^^^^^^^^^^^^^\n  File \"/Users/hwr/projects/llamda/llamda/problems/tsp_aco/eval.py\", line 28, in solve\n    heu = heuristics(dist_mat.copy()) + 1e-9\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/hwr/projects/llamda/llamda/problems/tsp_aco/gpt.py\", line 7, in heuristics_v2\n    with np.errstate(divide='ignore', invalid='ignore'):\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/hwr/projects/llamda/venv/lib/python3.11/site-packages/numpy/_core/fromnumeric.py\", line 3302, in min\n    return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/hwr/projects/llamda/venv/lib/python3.11/site-packages/numpy/_core/fromnumeric.py\", line 86, in _wrapreduction\n    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: reduction operation 'minimum' does not have an identity, so to use a where mask one has to specify 'initial'\n"
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    # Calculate the mean distance for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n    # Calculate the inverse of distances weighted by mean distances\n    with np.errstate(divide='ignore', invalid='ignore'):\n        promising_scores = mean_distances[:, np.newaxis] / distance_matrix\n        promising_scores[np.isnan(promising_scores)] = 0  # Handle infinity values\n    return promising_scores": {
    "exec_success": true,
    "obj": 6.492340982468976,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    # Applying a modified version of the original heuristic\n    with np.errstate(divide='ignore', invalid='ignore'):\n        filter_nan = np.where(distance_matrix == 0, np.nan, distance_matrix)  # to avoid division by zero\n        heuristic_scores = np.nan_to_num(1 / filter_nan, nan=0)  # Replace NaN with 0\n    # Modifying with additional heuristic criteria: prefer shorter edges with more connections\n    connectivity = np.reciprocals(np.sum(distance_matrix > 0, axis=0), where=(np.sum(distance_matrix > 0, axis=0) > 0))\n    return heuristic_scores * connectivity": {
    "exec_success": false,
    "obj": "inf",
    "traceback_msg": "Traceback (most recent call last):\n  File \"/Users/hwr/projects/llamda/llamda/problems/tsp_aco/eval.py\", line 57, in <module>\n    obj = solve(node_pos)\n          ^^^^^^^^^^^^^^^\n  File \"/Users/hwr/projects/llamda/llamda/problems/tsp_aco/eval.py\", line 28, in solve\n    heu = heuristics(dist_mat.copy()) + 1e-9\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/hwr/projects/llamda/llamda/problems/tsp_aco/gpt.py\", line 9, in heuristics_v2\n    normalized_distances = np.where(distance_matrix > 0, 1 - (distance_matrix / max_distance), 0)\n               ^^^^^^^^^^^^^^\n  File \"/Users/hwr/projects/llamda/venv/lib/python3.11/site-packages/numpy/__init__.py\", line 795, in __getattr__\n    raise AttributeError(f\"module {__name__!r} has no attribute {attr!r}\")\nAttributeError: module 'numpy' has no attribute 'reciprocals'. Did you mean: 'reciprocal'?\n"
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    # Calculate the maximum distance for normalization\n    max_distance = np.max(distance_matrix)\n    \n    # Create a heuristic by normalizing distance and taking inverse to prioritize shorter distances\n    with np.errstate(divide='ignore', invalid='ignore'):\n        normalized_distances = np.where(distance_matrix > 0, 1 - (distance_matrix / max_distance), 0)\n    \n    # Return the heuristics score by raising to a power to create non-linearity\n    heuristics_scores = normalized_distances ** 2\n    \n    # Ensure diagonal (self-loops) entries are zero\n    np.fill_diagonal(heuristics_scores, 0)\n    \n    return heuristics_scores": {
    "exec_success": true,
    "obj": 8.698430877040678,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculate promising edge indicators for TSP by combining inverse distances \n    and normalizing to emphasize proximity while avoiding zeros.\n    \"\"\"\n    eps = 1e-6  # Small value to avoid division by zero\n    inverted_distances = 1 / (distance_matrix + eps)\n    \n    # Set unpromising elements (high distances) to zero\n    inverted_distances[distance_matrix > np.percentile(distance_matrix, 75)] = 0\n    \n    # Normalize the promising distances\n    row_sum = inverted_distances.sum(axis=1)\n    heuristics_matrix = inverted_distances / (row_sum[:, np.newaxis] + eps)\n    \n    return heuristics_matrix": {
    "exec_success": true,
    "obj": 6.61704536265069,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculate edge heuristics for TSP by combining inverse distances\n    and row normalization, while setting unpromising elements to zero.\n    \"\"\"\n    eps = 1e-6  # Small value to avoid division by zero\n    inverted_distances = 1 / (distance_matrix + eps)\n    \n    # Use the inverse distances directly but set values to zero for longer edges\n    inverted_distances[distance_matrix > np.percentile(distance_matrix, 75)] = 0\n    \n    # Normalize rows to retain relative Prominence\n    row_sum = inverted_distances.sum(axis=1)\n    heuristics_matrix = inverted_distances / (row_sum[:, np.newaxis] + eps)\n    \n    return heuristics_matrix": {
    "exec_success": true,
    "obj": 6.599233773164222,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Heuristic function to estimate edge importance by combining inverses of distances\n    while sparsifying low-value connections to streamline decision-making for TSP.\n    \"\"\"\n    # Small value to avoid division by zero in edge cases\n    eps = 1e-6\n    \n    # Compute inverted distances\n    inverted_distances = 1 / (distance_matrix + eps)\n    \n    # Set a threshold to sparsify the matrix: retains top 50% edges\n    threshold = np.percentile(inverted_distances, 50, axis=1)\n    \n    # Create heuristics matrix with sparsifying condition\n    heuristics_matrix = np.where(inverted_distances >= threshold[:, np.newaxis], inverted_distances, 0)\n    \n    return heuristics_matrix": {
    "exec_success": true,
    "obj": 6.421449878245873,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines mean distance and inverse distance to score edges in TSP, prioritizing shorter edges\n    while maintaining simplicity and avoiding normalization complexities.\n    \"\"\"\n    # Calculate the mean distance for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n    \n    # Calculate the promising scores based on inverse distances\n    with np.errstate(divide='ignore', invalid='ignore'):\n        promising_scores = mean_distances[:, np.newaxis] / distance_matrix\n    \n    # Set unpromising distances (higher than mean) to zero\n    promising_scores[distance_matrix > mean_distances[:, np.newaxis]] = 0\n    \n    return promising_scores": {
    "exec_success": true,
    "obj": 6.4093803505326195,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculate promising scores for edges in TSP.\n    Combines inverse distances and mean distances for a clearer evaluation of edge potential.\n    \"\"\"\n    # Calculate inverse distances\n    inverse_distances = 1 / distance_matrix\n    \n    # Calculate mean distances\n    mean_distances = np.mean(distance_matrix, axis=1)\n    \n    # Calculate promising scores considering both factors\n    promising_scores = inverse_distances * mean_distances[:, np.newaxis]\n    \n    # Sparsify the matrix by setting unpromising elements to zero\n    promising_scores[distance_matrix == 0] = 0  # Remove self-loops\n    promising_scores[promising_scores < 0.1] = 0  # Set threshold\n    \n    return promising_scores": {
    "exec_success": true,
    "obj": 6.485903588110311,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculate promising scores for edges in TSP by combining inverse distances\n    and mean-based normalization, while setting low scores to zero.\n    \"\"\"\n    # Calculate the inverse of the distance matrix\n    inverse_distances = 1 / distance_matrix\n    \n    # Calculate the mean distances for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n    \n    # Combine the two heuristics\n    promising_scores = inverse_distances * (mean_distances[:, np.newaxis] / mean_distances.max())\n    \n    # Set unpromising edges to zero\n    promising_scores[np.isnan(promising_scores) | (promising_scores < 0.1)] = 0\n    \n    return promising_scores": {
    "exec_success": true,
    "obj": 6.534727305222837,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combines inverse distances and node mean distances to prioritize edges, avoiding complexity.\n    Outliers are reduced by sparsing unpromising edges, enhancing selection clarity.\n    \"\"\"\n    eps = 1e-6  # Small value to avoid division by zero\n    # Calculate the inverse distances\n    inverted_distances = 1 / (distance_matrix + eps)\n    \n    # Calculate mean distances for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n    \n    # Create promising scores by combining the two metrics\n    promising_scores = mean_distances[:, np.newaxis] * inverted_distances\n    \n    # Sparsify the matrix by setting unpromising elements to zero\n    promising_scores[promising_scores < np.mean(promising_scores)] = 0\n    \n    return promising_scores": {
    "exec_success": true,
    "obj": 6.298653934520914,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Heuristic design combining simplicity of inverse distance \n    with a mean distance prioritization to enhance promising edge identification.\n    \"\"\"\n    \n    # Calculate the mean distance for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n\n    # Calculate the inverse of distances while avoiding infinity values\n    with np.errstate(divide='ignore', invalid='ignore'):\n        inverse_distances = np.where(distance_matrix > 0, mean_distances[:, np.newaxis] / distance_matrix, 0)\n    \n    # Generate promising scores by combining both approaches\n    promising_scores = inverse_distances ** 2  # Introduce non-linearity for emphasis on shorter distances\n    \n    # Sparsify matrix by zeroing out unpromising scores (threshold can be adjusted for application)\n    promising_scores[promising_scores < 0.1] = 0\n    \n    # Ensure diagonal entries (self-loops) are zero\n    np.fill_diagonal(promising_scores, 0)\n    \n    return promising_scores": {
    "exec_success": true,
    "obj": 5.937757680410817,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combine inverse of distances and mean distance factors for promising edge selection.\n    Simplifies decision making while maintaining the core relationships in data.\n    \"\"\"\n\n    # Calculate the mean distance for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n    \n    # Calculate the inverse of distances\n    with np.errstate(divide='ignore', invalid='ignore'):\n        inverse_distances = mean_distances[:, np.newaxis] / distance_matrix\n        inverse_distances[np.isnan(inverse_distances)] = 0  # Handle infinity values\n    \n    # Combine the inverse distances with a sparse threshold\n    promising_scores = inverse_distances * (distance_matrix < np.mean(distance_matrix, axis=1, keepdims=True))\n\n    # Ensure diagonal (self-loops) entries are zero\n    np.fill_diagonal(promising_scores, 0)\n\n    return promising_scores": {
    "exec_success": true,
    "obj": 6.541656058107222,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combine simple inverse distance with normalization and sparsity for edge selection.\n    Prioritizes shorter distances while avoiding complex transformations.\n    \"\"\"\n    # Calculate the maximum distance for normalization\n    max_distance = np.max(distance_matrix)\n    \n    # Inverse of the distance matrix to prioritize shorter distances\n    inv_distance = 1 / distance_matrix\n    \n    # Normalize distances, but prevent negative values and ensure no self-loops\n    with np.errstate(divide='ignore', invalid='ignore'):\n        normalized_distances = np.where(distance_matrix > 0, 1 - (distance_matrix / max_distance), 0)\n    \n    # Combine inverses with normalized scores\n    combined_scores = inv_distance * normalized_distances\n    \n    # Set diagonal entries (self-loops) to zero to avoid self-selection\n    np.fill_diagonal(combined_scores, 0)\n    \n    # Sparsify by thresholding low scores to zero\n    threshold = np.mean(combined_scores[combined_scores > 0])  # Can adjust threshold as necessary\n    combined_scores[combined_scores < threshold] = 0\n    \n    return combined_scores": {
    "exec_success": true,
    "obj": 6.254470122057964,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Improved heuristic design for TSP using a combination of \n    relative distances, node centrality, and edge density to enhance \n    edge selection for promising paths more effectively.\n    \"\"\"\n    \n    # Calculate the mean distance for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n\n    # Calculate the variance of distances to understand spread\n    distance_variance = np.var(distance_matrix, axis=1)\n\n    # Calculate metrics that balance proximity and node centrality\n    proximity_scores = mean_distances / (distance_variance + 1e-5)  # Avoid division by zero\n    \n    # Calculate inverse distances while avoiding infinity values\n    with np.errstate(divide='ignore', invalid='ignore'):\n        inverse_distances = np.where(distance_matrix > 0, 1 / distance_matrix, 0)\n\n    # Combine the scores to emphasize promising edges\n    promising_scores = proximity_scores[:, np.newaxis] * inverse_distances\n    \n    # Sparsify the matrix by zeroing out unpromising scores (threshold can be adjusted for application)\n    promising_scores[promising_scores < 0.05] = 0\n    \n    # Ensure diagonal entries (self-loops) are zero\n    np.fill_diagonal(promising_scores, 0)\n    \n    return promising_scores": {
    "exec_success": true,
    "obj": 6.618808721017581,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Improved heuristic design for edge selection based on relative contributions\n    of distances and node connectivity, enhancing the identification of promising edges\n    in the context of the Traveling Salesman Problem (TSP).\n    \"\"\"\n    \n    # Calculate the mean distances for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n    \n    # Influence of each edge determined by how much closer it gets to the mean distance\n    closeness_factor = mean_distances[:, np.newaxis] - distance_matrix\n    \n    # Exclude edges that do not connect two different nodes\n    closeness_factor[distance_matrix == 0] = -np.inf\n    \n    # Compute a score based on the closeness factor, emphasizing connections that approach mean distances\n    promising_scores = np.clip(closeness_factor, 0, None) ** 2\n    \n    # Combine with an inverse distance to further emphasize shorter, more beneficial edges\n    with np.errstate(divide='ignore', invalid='ignore'):\n        inverse_distances = np.where(distance_matrix > 0, 1 / distance_matrix, 0)\n\n    # Calculate the final promising scores by combining both approaches (weighted)\n    final_scores = promising_scores * inverse_distances\n\n    # Apply a sparsification process to zero-out unpromising scores\n    threshold = np.percentile(final_scores, 75)  # Keep only the top 25% of edge scores\n    final_scores[final_scores < threshold] = 0\n    \n    # Ensure diagonal entries (self-loops) are zero\n    np.fill_diagonal(final_scores, 0)\n    \n    return final_scores": {
    "exec_success": true,
    "obj": 5.933505526538141,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Enhanced heuristic design prioritizing edge selection\n    based on relative distance efficiency and node connectivity.\n    \"\"\"\n    \n    # Calculate the mean distance for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n    \n    # Calculate the relative importance of each edge based on distance\n    # using the mean distance to normalize scores\n    relative_scores = mean_distances[:, np.newaxis] / (distance_matrix + 1e-5)  # Avoid division by zero\n    \n    # Calculate connectivity score based on the number of edges connecting to each node\n    connectivity_scores = np.sum(distance_matrix > 0, axis=1)[:, np.newaxis]\n    \n    # Combine the relative scores with the connectivity scores\n    combined_scores = relative_scores * connectivity_scores\n    \n    # Apply a non-linear transformation for emphasis on selecting shorter, more connected edges\n    promising_scores = combined_scores ** 1.5 \n    \n    # Sparsify matrix by zeroing out unpromising scores (threshold can be adjusted)\n    promising_scores[promising_scores < 0.2] = 0\n    \n    # Ensure diagonal entries (self-loops) are zero\n    np.fill_diagonal(promising_scores, 0)\n    \n    return promising_scores": {
    "exec_success": true,
    "obj": 6.115473746072293,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Enhanced heuristic design for TSP combining \n    edge distance, node connectivity, and clustering to prioritize promising edges.\n    \"\"\"\n    \n    num_nodes = distance_matrix.shape[0]\n    \n    # Calculate the mean distance for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n\n    # Calculate connectivity scores based on the number of connections\n    connectivity_scores = np.sum(distance_matrix > 0, axis=1) / (num_nodes - 1)\n\n    # Calculate inverse distances but reserve high scores for short distances\n    with np.errstate(divide='ignore', invalid='ignore'):\n        inverse_distances = np.where(distance_matrix > 0, mean_distances[:, np.newaxis] / distance_matrix, 0)\n    \n    # Combine scores with a balance towards shorter connections and connectivity\n    promising_scores = (inverse_distances * connectivity_scores[:, np.newaxis]) ** 1.5\n    \n    # Sparsify matrix by zeroing out low scores based on a dynamic threshold\n    threshold = np.percentile(promising_scores, 75)\n    promising_scores[promising_scores < threshold] = 0\n    \n    # Ensure diagonal entries (self-loops) are zero\n    np.fill_diagonal(promising_scores, 0)\n    \n    return promising_scores": {
    "exec_success": true,
    "obj": 5.965279114895031,
    "traceback_msg": null
  },
  "import numpy as np\n\ndef heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Enhanced heuristic combining the influence of distance, node connectivity, \n    and minimum edge evaluation to better assess promising edges for the TSP.\n    \"\"\"\n    \n    num_nodes = distance_matrix.shape[0]\n    \n    # Calculate the mean and median distance for each node to assess overall connectivity\n    mean_distances = np.mean(distance_matrix, axis=1)\n    median_distances = np.median(distance_matrix, axis=1)\n\n    # Calculate connectivity based on the count of non-infinite distances\n    connectivity_scores = np.count_nonzero(distance_matrix, axis=1) / num_nodes\n\n    # Calculate inverse distance metrics\n    with np.errstate(divide='ignore', invalid='ignore'):\n        inverse_distances = np.where(distance_matrix > 0, mean_distances[:, np.newaxis] / distance_matrix, 0)\n\n    # Combine factors: prioritizing edges with lower distances and higher connectivity\n    promising_scores = (inverse_distances ** 2) * connectivity_scores[:, np.newaxis]\n    \n    # Calculate minimum edges for each node to enhance local connectivity emphasis\n    min_edges = np.min(distance_matrix + np.eye(num_nodes) * np.inf, axis=1)\n    min_edges_matrix = min_edges[:, np.newaxis] / distance_matrix\n\n    # Factor in the minimum edges to prioritize local paths\n    promising_scores *= min_edges_matrix\n\n    # Sparsify by zeroing out unpromising scores\n    promising_scores[promising_scores < 0.05] = 0\n    \n    # Ensure diagonal entries (self-loops) are zero\n    np.fill_diagonal(promising_scores, 0)\n    \n    return promising_scores": {
    "exec_success": false,
    "obj": "inf",
    "traceback_msg": "Traceback (most recent call last):\n  File \"/Users/hwr/projects/llamda/llamda/problems/tsp_aco/eval.py\", line 57, in <module>\n    obj = solve(node_pos)\n          ^^^^^^^^^^^^^^^\n  File \"/Users/hwr/projects/llamda/llamda/problems/tsp_aco/eval.py\", line 31, in solve\n    obj = aco.run(N_ITERATIONS)\n          ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/hwr/projects/llamda/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/hwr/projects/llamda/llamda/problems/tsp_aco/aco.py\", line 37, in run\n    paths = self.gen_path(require_prob=False)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/hwr/projects/llamda/llamda/problems/tsp_aco/aco.py\", line 99, in gen_path\n    actions, log_probs = self.pick_move(prev, mask, require_prob)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/hwr/projects/llamda/llamda/problems/tsp_aco/aco.py\", line 123, in pick_move\n    dist = Categorical(dist)\n           ^^^^^^^^^^^^^^^^^\n  File \"/Users/hwr/projects/llamda/venv/lib/python3.11/site-packages/torch/distributions/categorical.py\", line 81, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/Users/hwr/projects/llamda/venv/lib/python3.11/site-packages/torch/distributions/distribution.py\", line 77, in __init__\n    raise ValueError(\nValueError: Expected parameter probs (Tensor of shape (30, 50)) of distribution Categorical(probs: torch.Size([30, 50])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64)\n"
  },
  "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray, threshold_percentile: float = 72.19987722668247) -> np.ndarray:\n    \"\"\"\n    Improved heuristic design for edge selection based on relative contributions\n    of distances and node connectivity, enhancing the identification of promising edges\n    in the context of the Traveling Salesman Problem (TSP).\n    \"\"\"\n    \n    # Calculate the mean distances for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n    \n    # Influence of each edge determined by how much closer it gets to the mean distance\n    closeness_factor = mean_distances[:, np.newaxis] - distance_matrix\n    \n    # Exclude edges that do not connect two different nodes\n    closeness_factor[distance_matrix == 0] = -np.inf\n    \n    # Compute a score based on the closeness factor, emphasizing connections that approach mean distances\n    promising_scores = np.clip(closeness_factor, 0, None) ** 2\n    \n    # Combine with an inverse distance to further emphasize shorter, more beneficial edges\n    with np.errstate(divide='ignore', invalid='ignore'):\n        inverse_distances = np.where(distance_matrix > 0, 1 / distance_matrix, 0)\n\n    # Calculate the final promising scores by combining both approaches (weighted)\n    final_scores = promising_scores * inverse_distances\n\n    # Apply a sparsification process to zero-out unpromising scores\n    threshold = np.percentile(final_scores, threshold_percentile)  # Keep only the top threshold_percentile% of edge scores\n    final_scores[final_scores < threshold] = 0\n    \n    # Ensure diagonal entries (self-loops) are zero\n    np.fill_diagonal(final_scores, 0)\n    \n    return final_scores": {
    "exec_success": true,
    "obj": 5.9719520693366865,
    "traceback_msg": null
  },
  "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray, threshold_percentile: float = 93.85527090157501) -> np.ndarray:\n    \"\"\"\n    Improved heuristic design for edge selection based on relative contributions\n    of distances and node connectivity, enhancing the identification of promising edges\n    in the context of the Traveling Salesman Problem (TSP).\n    \"\"\"\n    \n    # Calculate the mean distances for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n    \n    # Influence of each edge determined by how much closer it gets to the mean distance\n    closeness_factor = mean_distances[:, np.newaxis] - distance_matrix\n    \n    # Exclude edges that do not connect two different nodes\n    closeness_factor[distance_matrix == 0] = -np.inf\n    \n    # Compute a score based on the closeness factor, emphasizing connections that approach mean distances\n    promising_scores = np.clip(closeness_factor, 0, None) ** 2\n    \n    # Combine with an inverse distance to further emphasize shorter, more beneficial edges\n    with np.errstate(divide='ignore', invalid='ignore'):\n        inverse_distances = np.where(distance_matrix > 0, 1 / distance_matrix, 0)\n\n    # Calculate the final promising scores by combining both approaches (weighted)\n    final_scores = promising_scores * inverse_distances\n\n    # Apply a sparsification process to zero-out unpromising scores\n    threshold = np.percentile(final_scores, threshold_percentile)  # Keep only the top threshold_percentile% of edge scores\n    final_scores[final_scores < threshold] = 0\n    \n    # Ensure diagonal entries (self-loops) are zero\n    np.fill_diagonal(final_scores, 0)\n    \n    return final_scores": {
    "exec_success": true,
    "obj": 6.756980853814033,
    "traceback_msg": null
  },
  "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray, threshold_percentile: float = 0.07787658410143283) -> np.ndarray:\n    \"\"\"\n    Improved heuristic design for edge selection based on relative contributions\n    of distances and node connectivity, enhancing the identification of promising edges\n    in the context of the Traveling Salesman Problem (TSP).\n    \"\"\"\n    \n    # Calculate the mean distances for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n    \n    # Influence of each edge determined by how much closer it gets to the mean distance\n    closeness_factor = mean_distances[:, np.newaxis] - distance_matrix\n    \n    # Exclude edges that do not connect two different nodes\n    closeness_factor[distance_matrix == 0] = -np.inf\n    \n    # Compute a score based on the closeness factor, emphasizing connections that approach mean distances\n    promising_scores = np.clip(closeness_factor, 0, None) ** 2\n    \n    # Combine with an inverse distance to further emphasize shorter, more beneficial edges\n    with np.errstate(divide='ignore', invalid='ignore'):\n        inverse_distances = np.where(distance_matrix > 0, 1 / distance_matrix, 0)\n\n    # Calculate the final promising scores by combining both approaches (weighted)\n    final_scores = promising_scores * inverse_distances\n\n    # Apply a sparsification process to zero-out unpromising scores\n    threshold = np.percentile(final_scores, threshold_percentile)  # Keep only the top threshold_percentile% of edge scores\n    final_scores[final_scores < threshold] = 0\n    \n    # Ensure diagonal entries (self-loops) are zero\n    np.fill_diagonal(final_scores, 0)\n    \n    return final_scores": {
    "exec_success": true,
    "obj": 5.941424331121626,
    "traceback_msg": null
  },
  "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray, threshold_percentile: float = 99.22115592912175) -> np.ndarray:\n    \"\"\"\n    Improved heuristic design for edge selection based on relative contributions\n    of distances and node connectivity, enhancing the identification of promising edges\n    in the context of the Traveling Salesman Problem (TSP).\n    \"\"\"\n    \n    # Calculate the mean distances for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n    \n    # Influence of each edge determined by how much closer it gets to the mean distance\n    closeness_factor = mean_distances[:, np.newaxis] - distance_matrix\n    \n    # Exclude edges that do not connect two different nodes\n    closeness_factor[distance_matrix == 0] = -np.inf\n    \n    # Compute a score based on the closeness factor, emphasizing connections that approach mean distances\n    promising_scores = np.clip(closeness_factor, 0, None) ** 2\n    \n    # Combine with an inverse distance to further emphasize shorter, more beneficial edges\n    with np.errstate(divide='ignore', invalid='ignore'):\n        inverse_distances = np.where(distance_matrix > 0, 1 / distance_matrix, 0)\n\n    # Calculate the final promising scores by combining both approaches (weighted)\n    final_scores = promising_scores * inverse_distances\n\n    # Apply a sparsification process to zero-out unpromising scores\n    threshold = np.percentile(final_scores, threshold_percentile)  # Keep only the top threshold_percentile% of edge scores\n    final_scores[final_scores < threshold] = 0\n    \n    # Ensure diagonal entries (self-loops) are zero\n    np.fill_diagonal(final_scores, 0)\n    \n    return final_scores": {
    "exec_success": true,
    "obj": 16.851578726200295,
    "traceback_msg": null
  },
  "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray, threshold_percentile: float = 61.74815096277165) -> np.ndarray:\n    \"\"\"\n    Improved heuristic design for edge selection based on relative contributions\n    of distances and node connectivity, enhancing the identification of promising edges\n    in the context of the Traveling Salesman Problem (TSP).\n    \"\"\"\n    \n    # Calculate the mean distances for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n    \n    # Influence of each edge determined by how much closer it gets to the mean distance\n    closeness_factor = mean_distances[:, np.newaxis] - distance_matrix\n    \n    # Exclude edges that do not connect two different nodes\n    closeness_factor[distance_matrix == 0] = -np.inf\n    \n    # Compute a score based on the closeness factor, emphasizing connections that approach mean distances\n    promising_scores = np.clip(closeness_factor, 0, None) ** 2\n    \n    # Combine with an inverse distance to further emphasize shorter, more beneficial edges\n    with np.errstate(divide='ignore', invalid='ignore'):\n        inverse_distances = np.where(distance_matrix > 0, 1 / distance_matrix, 0)\n\n    # Calculate the final promising scores by combining both approaches (weighted)\n    final_scores = promising_scores * inverse_distances\n\n    # Apply a sparsification process to zero-out unpromising scores\n    threshold = np.percentile(final_scores, threshold_percentile)  # Keep only the top threshold_percentile% of edge scores\n    final_scores[final_scores < threshold] = 0\n    \n    # Ensure diagonal entries (self-loops) are zero\n    np.fill_diagonal(final_scores, 0)\n    \n    return final_scores": {
    "exec_success": true,
    "obj": 5.999105157299884,
    "traceback_msg": null
  },
  "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray, threshold_percentile: float = 53.39731657069333) -> np.ndarray:\n    \"\"\"\n    Improved heuristic design for edge selection based on relative contributions\n    of distances and node connectivity, enhancing the identification of promising edges\n    in the context of the Traveling Salesman Problem (TSP).\n    \"\"\"\n    \n    # Calculate the mean distances for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n    \n    # Influence of each edge determined by how much closer it gets to the mean distance\n    closeness_factor = mean_distances[:, np.newaxis] - distance_matrix\n    \n    # Exclude edges that do not connect two different nodes\n    closeness_factor[distance_matrix == 0] = -np.inf\n    \n    # Compute a score based on the closeness factor, emphasizing connections that approach mean distances\n    promising_scores = np.clip(closeness_factor, 0, None) ** 2\n    \n    # Combine with an inverse distance to further emphasize shorter, more beneficial edges\n    with np.errstate(divide='ignore', invalid='ignore'):\n        inverse_distances = np.where(distance_matrix > 0, 1 / distance_matrix, 0)\n\n    # Calculate the final promising scores by combining both approaches (weighted)\n    final_scores = promising_scores * inverse_distances\n\n    # Apply a sparsification process to zero-out unpromising scores\n    threshold = np.percentile(final_scores, threshold_percentile)  # Keep only the top threshold_percentile% of edge scores\n    final_scores[final_scores < threshold] = 0\n    \n    # Ensure diagonal entries (self-loops) are zero\n    np.fill_diagonal(final_scores, 0)\n    \n    return final_scores": {
    "exec_success": true,
    "obj": 5.9507903879097555,
    "traceback_msg": null
  },
  "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray, threshold_percentile: float = 112.80549165523338) -> np.ndarray:\n    \"\"\"\n    Improved heuristic design for edge selection based on relative contributions\n    of distances and node connectivity, enhancing the identification of promising edges\n    in the context of the Traveling Salesman Problem (TSP).\n    \"\"\"\n    \n    # Calculate the mean distances for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n    \n    # Influence of each edge determined by how much closer it gets to the mean distance\n    closeness_factor = mean_distances[:, np.newaxis] - distance_matrix\n    \n    # Exclude edges that do not connect two different nodes\n    closeness_factor[distance_matrix == 0] = -np.inf\n    \n    # Compute a score based on the closeness factor, emphasizing connections that approach mean distances\n    promising_scores = np.clip(closeness_factor, 0, None) ** 2\n    \n    # Combine with an inverse distance to further emphasize shorter, more beneficial edges\n    with np.errstate(divide='ignore', invalid='ignore'):\n        inverse_distances = np.where(distance_matrix > 0, 1 / distance_matrix, 0)\n\n    # Calculate the final promising scores by combining both approaches (weighted)\n    final_scores = promising_scores * inverse_distances\n\n    # Apply a sparsification process to zero-out unpromising scores\n    threshold = np.percentile(final_scores, threshold_percentile)  # Keep only the top threshold_percentile% of edge scores\n    final_scores[final_scores < threshold] = 0\n    \n    # Ensure diagonal entries (self-loops) are zero\n    np.fill_diagonal(final_scores, 0)\n    \n    return final_scores": {
    "exec_success": false,
    "obj": "inf",
    "traceback_msg": "Traceback (most recent call last):\n  File \"/Users/hwr/projects/llamda/llamda/problems/tsp_aco/eval.py\", line 57, in <module>\n    obj = solve(node_pos)\n          ^^^^^^^^^^^^^^^\n  File \"/Users/hwr/projects/llamda/llamda/problems/tsp_aco/eval.py\", line 28, in solve\n    heu = heuristics(dist_mat.copy()) + 1e-9\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/hwr/projects/llamda/llamda/problems/tsp_aco/gpt.py\", line 33, in heuristics_v2\n    threshold = np.percentile(final_scores, threshold_percentile)  # Keep only the top threshold_percentile% of edge scores\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/hwr/projects/llamda/venv/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py\", line 4279, in percentile\n    raise ValueError(\"Percentiles must be in the range [0, 100]\")\nValueError: Percentiles must be in the range [0, 100]\n"
  },
  "import numpy as np\nimport random\nimport math\nimport scipy\nimport torch\ndef heuristics_v2(distance_matrix: np.ndarray, threshold_percentile: float = 19.407112016372963) -> np.ndarray:\n    \"\"\"\n    Improved heuristic design for edge selection based on relative contributions\n    of distances and node connectivity, enhancing the identification of promising edges\n    in the context of the Traveling Salesman Problem (TSP).\n    \"\"\"\n    \n    # Calculate the mean distances for each node\n    mean_distances = np.mean(distance_matrix, axis=1)\n    \n    # Influence of each edge determined by how much closer it gets to the mean distance\n    closeness_factor = mean_distances[:, np.newaxis] - distance_matrix\n    \n    # Exclude edges that do not connect two different nodes\n    closeness_factor[distance_matrix == 0] = -np.inf\n    \n    # Compute a score based on the closeness factor, emphasizing connections that approach mean distances\n    promising_scores = np.clip(closeness_factor, 0, None) ** 2\n    \n    # Combine with an inverse distance to further emphasize shorter, more beneficial edges\n    with np.errstate(divide='ignore', invalid='ignore'):\n        inverse_distances = np.where(distance_matrix > 0, 1 / distance_matrix, 0)\n\n    # Calculate the final promising scores by combining both approaches (weighted)\n    final_scores = promising_scores * inverse_distances\n\n    # Apply a sparsification process to zero-out unpromising scores\n    threshold = np.percentile(final_scores, threshold_percentile)  # Keep only the top threshold_percentile% of edge scores\n    final_scores[final_scores < threshold] = 0\n    \n    # Ensure diagonal entries (self-loops) are zero\n    np.fill_diagonal(final_scores, 0)\n    \n    return final_scores": {
    "exec_success": true,
    "obj": 5.89614290303648,
    "traceback_msg": null
  }
}